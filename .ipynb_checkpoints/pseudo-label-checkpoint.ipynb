{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install snorkel\n",
    "#!pip install epitator\n",
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from snorkel.labeling import PandasLFApplier,LFAnalysis,LabelingFunction\n",
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path information\n",
    "task='task1'# or 'task2' # specify task\n",
    "root_path='/repo1/code/autoreview/'\n",
    "data_path=root_path+'data/'+task+'/'#path to save retrieved articles abstract\n",
    "keyword_path=data_path+'keywords/'#keyword list\n",
    "save_path=root_path+'results/'+task+'/'\n",
    "sentence_file_name='hypercoagulable.pkl'\n",
    "sentence_embedding_file_name='sentence_embedding.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentence_df():\n",
    "    \"\"\"\n",
    "    Load sentence-wise pd.Dataframe that are save from `get_articles.ipynb` \n",
    "    \"\"\"\n",
    "    \n",
    "    sentences=pkl.load(open(data_path+sentence_file_name, 'rb'))\n",
    "    sentences_embedding=pkl.load(open(data_path+sentences_embedding_file_name, 'rb'))\n",
    "    \n",
    "    return sentences, sentences_embedding\n",
    "# def build_sentence_df():\n",
    "#     \"\"\"\n",
    "#     Read articles files (data_path+article_name) and save it as `sentences` a sentence-wise pd.dataframe\n",
    "#     Refined from `build_raw_data`\n",
    "    \n",
    "#     output:\n",
    "#         sentences: pd.Dataframe with ['pid', 'sid', 'sent']. 'sid'=sentence ID\n",
    "#     \"\"\"\n",
    "#     articles=pd.read_excel(data_path+articles_name)\n",
    "#     sentences=articles['abstract'].apply(sent_tokenize)\\\n",
    "#                     .apply(pd.Series)\\\n",
    "#                     .merge(articles, left_index = True, right_index=True)\\\n",
    "#                     .drop('abstract', axis=1)\\\n",
    "#                     .melt(id_vars=['pid','title'], value_name='sent')\\\n",
    "#                     .drop('variable', axis=1).dropna()\n",
    "    \n",
    "#     return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keyword(keyword_file_name):\n",
    "    \"\"\"\n",
    "    Read keyword list\n",
    "    \n",
    "    input:\n",
    "        keyword_type_name: str, file name, e.g., `keylist.txt`\n",
    "    output:\n",
    "        list of string, e.g., ['keyword1', 'keyword2', 'keyword3']\n",
    "        \n",
    "    \"\"\"\n",
    "    with open(keyword_path+keyword_file_name, \"r\") as f:\n",
    "        keylist=f.read().split(',')\n",
    "    return keylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_function(virus_list, efficacy_list, drug_list):\n",
    "    \"\"\"\n",
    "    Generate all label functions\n",
    "    Refined  from `loop_labing`\n",
    "    \n",
    "    input:\n",
    "        keywords: list of string ['keyword1', 'keyword2', 'keyword3']\n",
    "    output:\n",
    "        lfs: list of snorkel.LabelingFunction\n",
    "    \"\"\"\n",
    "    \n",
    "    def keyword_lookup(df, keywords, label):\n",
    "        if any(keyword in df.sent for keyword in keywords):\n",
    "            return label\n",
    "        return abstain\n",
    "    \n",
    "    def make_keyword_lf(keywords,name,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"keyword_{name}\",\n",
    "            f=keyword_lookup,\n",
    "            resources=dict(keywords=keywords, label=label)\n",
    "        )\n",
    "    \n",
    "    abstain=-1\n",
    "    virus_lf=make_keyword_lf(keywords=virus_list, name='virus', label=1)\n",
    "    efficacy_lf=make_keyword_lf(keywords=efficacy_list, name='efficacy', label=1)\n",
    "    drug_lf=make_keyword_lf(keywords=drug_list, name='drug', label=1)\n",
    "\n",
    "    return [virus_lf, efficacy_lf, drug_lf]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_prob(lfs):\n",
    "    \"\"\"\n",
    "    Predict probability (label) by applying label functions lfs\n",
    "    Refined from `snorkel_process` \n",
    "    \n",
    "    input:\n",
    "        lfs: list of snorkel.LabelingFunction\n",
    "    output:\n",
    "        sentences_labeled: pd.Dataframe,  [pid, sid, sent, label, prob ]\n",
    "    \"\"\"\n",
    "    \n",
    "    applier=PandasLFApplier(lfs=lfs)\n",
    "    applied=applier.apply(df=sentences)\n",
    "    print(LFAnalysis(L=applied, lfs=lfs).lf_summary())\n",
    "    \n",
    "    label_model = LabelModel()\n",
    "    label_model.fit(applied)\n",
    "    sentences['label']=label_model.predict(applied)\n",
    "    sentences['prob']=label_model.predict_proba(applied)[:,1]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 1209/1209 [00:06<00:00, 191.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  j Polarity  Coverage  Overlaps  Conflicts\n",
      "keyword_virus     0      [1]  0.229942  0.007444        0.0\n",
      "keyword_efficacy  1      [1]  0.033912  0.003309        0.0\n",
      "keyword_drug      2      [1]  0.019024  0.004963        0.0\n"
     ]
    }
   ],
   "source": [
    "### make pd.Dataframe for sentences\n",
    "sentences, sentence_embedding = load_sentence_df()\n",
    "#sentences = build_sentence_df()\n",
    "\n",
    "### load keyword lists\n",
    "#keyword_file_names=['keylist.txt', 'valuelist.txt']\n",
    "virus_list=load_keyword('virus.txt')\n",
    "efficacy_list=load_keyword('efficacy.txt')\n",
    "drug_list=load_keyword('drug.txt')\n",
    "\n",
    "### Generate label functions\n",
    "lfs = generate_label_function(virus_list, efficacy_list, drug_list)\n",
    "\n",
    "### Apply label functions to sentences and generate pseudo labels\n",
    "sentences_labeled = predict_prob(lfs)\n",
    "\n",
    "### Save as tsv file\n",
    "sentences_labeled.to_csv(save_path+'pseudo-label.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
