{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import os\n",
    "from snorkel.labeling import PandasLFApplier,LFAnalysis,LabelingFunction\n",
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "from snorkel.labeling.apply.dask import PandasParallelLFApplier\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime, date, time\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold=pd.read_csv('hypercoagulable_sentences.csv')\n",
    "gold=gold.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8766/8766 [00:13<00:00, 638.06it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ab=[]\n",
    "ncord=[]\n",
    "for i in tqdm(gold.ncord_uid.drop_duplicates()):\n",
    "    temp=gold[gold.ncord_uid==i]\n",
    "    tempsent=temp.sentence.values\n",
    "    tempncord=temp.ncord_uid.drop_duplicates().values[0]\n",
    "    init=''\n",
    "    for j in tempsent:\n",
    "        init=init+j\n",
    "    ab.append(init)\n",
    "    ncord.append(tempncord)\n",
    "goldab=pd.DataFrame(ncord,columns=['ncord_uid'])\n",
    "goldab['abstract']=ab\n",
    "goldab=goldab.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "triallist=['single group assignment','parallel assignment','crossover assignment','sequential sssignment','factorial assignment'\n",
    "           ,'cohort','case only','case-control','case control','ecologic or Community','family based'  \n",
    "         ,'open label','double blind','single blind','triple blind','quadruple blind',\n",
    "         'double-blind','single-blind','triple-blind','quadruple-blind'\n",
    "          ,'treatment','supportive care'\n",
    "        ,'randomized','non-Randomized','non-Randomized'\n",
    "         ]\n",
    "\n",
    "keywordslist=['coagulation','D-dimer','thromboelastometry','anticoagulants','venous thromboembolism','clot formation time'\n",
    ",'Maximum Clot Firmness', 'PT', 'aPTT', 'thrombin time','platelet','fibrinogen','antiphospholipid antibody',\n",
    "'heparin induced thrombocytopenia','prothrombin time','platelet count','factor v','factor ii','protein c','protein s',\n",
    "'antithrombin iii','leiden/apc','c-reactive protein','coagulopathy','disseminated intravascular coagulation',\n",
    "'thrombotic microangiopathy','thrombotic manifestations','sic score','venous thromboembolic','arterial thrombosis'\n",
    ",'thrombosis','heparin','tissue plasminogen activator','anticoagulants','prophylactic','anticoagulation'\n",
    "             ]\n",
    "viruslist=['covid-19','covid 19','sars cov 2','sars-cov-2','sars like cov']\n",
    "mustlist=['hypercoagulable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_labing(keywordslist,viruslist,triallist,mustlist,maxngramnu):\n",
    "    \n",
    "    \n",
    "    def keyword_lookup(x,keywords,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_keyword_lf(keywords,maxngram,name,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"keyword_{name}\",\n",
    "            f=keyword_lookup,\n",
    "            resources=dict(keywords=keywords,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def keyword_lookup_b(x,keywords,must,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords) and any(word1 in wordlist  for word1 in must):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_keyword_b_lf(keywords,must,maxngram,name,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"keyword_b_{name}\",\n",
    "            f=keyword_lookup_b,\n",
    "            resources=dict(keywords=keywords,must=must,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def trial_lookup(x,trial,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in trial):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_trial_lf(trial,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"trial\",\n",
    "            f=trial_lookup,\n",
    "            resources=dict(trial=trial,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def not_lookup(x,keywords,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold=threshold+1\n",
    "        if threshold<1 and threshold1>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_not_lf(keywords,name,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"not_{name}\",\n",
    "            f=not_lookup_b,\n",
    "            resources=dict(keywords=keywords,maxngram=maxngram,label=label),)  \n",
    "    \n",
    "    def not_lookup_b(x,keywords,virus,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in virus):\n",
    "                    threshold=threshold+1\n",
    "        threshold1=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold1=threshold1+1\n",
    "        if threshold<1 and threshold1>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_not_b_lf(keywords,virus,name,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"not_b_{name}\",\n",
    "            f=not_lookup_b,\n",
    "            resources=dict(keywords=keywords,virus=virus,maxngram=maxngram,label=label),)   \n",
    "    \n",
    "    def number_lookup(x,trial,label):\n",
    "        threshold=0\n",
    "        sentlist=x.abstract.split()\n",
    "        trialindex=[i for i, e in enumerate(sentlist) if e in trial]\n",
    "        nuindex=[i for i, e in enumerate(sentlist) if str(e).isdigit()]\n",
    "        for i in trialindex:\n",
    "            for j in nuindex:\n",
    "                if i<j:\n",
    "                    threshold+=1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_number_lf(trial,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"number\",\n",
    "            f=number_lookup,\n",
    "            resources=dict(trial=trial,label=label),)\n",
    "\n",
    "   \n",
    "    \n",
    "    Norelevent = -1\n",
    "    \n",
    "    keywordfu=make_keyword_lf(keywords=keywordslist,maxngram=maxngramnu,name='keyword',label=1)    \n",
    "    virusfu=make_keyword_lf(keywords=viruslist,maxngram=maxngramnu,name='virus',label=1)\n",
    "    keywordfub=make_keyword_b_lf(keywords=keywordslist,must=mustlist,maxngram=maxngramnu,name='keyword',label=1)    \n",
    "    virusfub=make_keyword_b_lf(keywords=viruslist,must=mustlist,maxngram=maxngramnu,name='virus',label=1)\n",
    "    trialfu=make_trial_lf(trial=triallist,maxngram=maxngramnu,label=1)\n",
    "    notfu1=make_not_b_lf(keywords=mustlist,virus=keywordslist,maxngram=maxngramnu,name='notkeyword',label=0)\n",
    "    notfu2=make_not_b_lf(keywords=keywordslist,virus=triallist,maxngram=maxngramnu,name='nottrial',label=0)\n",
    "    numberfu=make_number_lf(trial=triallist,label=1)\n",
    "    \n",
    "    allweaklabf=[]\n",
    "\n",
    "    allweaklabf.append(keywordfu)\n",
    "    allweaklabf.append(virusfu)\n",
    "    allweaklabf.append(keywordfub)\n",
    "    allweaklabf.append(virusfub)\n",
    "    allweaklabf.append(trialfu)\n",
    "    allweaklabf.append(notfu1)\n",
    "    allweaklabf.append(notfu2)\n",
    "    allweaklabf.append(numberfu)\n",
    "\n",
    "    \n",
    "    return allweaklabf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8766/8766 [02:43<00:00, 53.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   j Polarity  Coverage  Overlaps  Conflicts\n",
      "keyword_keyword    0      [1]  0.236140  0.236140   0.130504\n",
      "keyword_virus      1      [1]  0.060461  0.048597   0.004905\n",
      "keyword_b_keyword  2       []  0.000000  0.000000   0.000000\n",
      "keyword_b_virus    3      [1]  0.000570  0.000570   0.000570\n",
      "trial              4      [1]  0.621948  0.497718   0.000684\n",
      "not_b_notkeyword   5      [0]  0.001141  0.000799   0.000799\n",
      "not_b_nottrial     6      [0]  0.130504  0.130504   0.130504\n",
      "number             7      [1]  0.450605  0.450605   0.000228\n"
     ]
    }
   ],
   "source": [
    "cardinalitynu=2\n",
    "allweaklabf=loop_labing(keywordslist,viruslist,triallist,mustlist,3)\n",
    "applier = PandasLFApplier(lfs=allweaklabf)\n",
    "all_train_l = applier.apply(df=gold)\n",
    "#applier = PandasParallelLFApplier(lfs=allweaklabf)\n",
    "#all_train_l = applier.apply(df=allframe1,n_parallel=40)\n",
    "report=LFAnalysis(L=all_train_l, lfs=allweaklabf).lf_summary()\n",
    "print(report)\n",
    "label_model = LabelModel(cardinality=cardinalitynu,verbose=True)\n",
    "label_model.fit(all_train_l)\n",
    "predt=label_model.predict(all_train_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldab['label']=predt\n",
    "prob=label_model.predict_proba(all_train_l)[:,1]\n",
    "goldab['prob_snokel']=prob\n",
    "goldab1=goldab[goldab.label==1]\n",
    "goldab1=goldab1.drop_duplicates()\n",
    "goldab1=goldab1.sort_values(by='prob_snokel',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldab.to_pickle('./round_2ab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_labing(keywordslist,viruslist,triallist,mustlist,maxngramnu):\n",
    "    \n",
    "    \n",
    "    def keyword_lookup(x,keywords,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_keyword_lf(keywords,maxngram,name,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"keyword_{name}\",\n",
    "            f=keyword_lookup,\n",
    "            resources=dict(keywords=keywords,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def keyword_lookup_b(x,keywords,must,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords) and any(word1 in wordlist  for word1 in must):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_keyword_b_lf(keywords,must,maxngram,name,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"keyword_b_{name}\",\n",
    "            f=keyword_lookup_b,\n",
    "            resources=dict(keywords=keywords,must=must,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def trial_lookup(x,trial,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in trial):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_trial_lf(trial,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"trial\",\n",
    "            f=trial_lookup,\n",
    "            resources=dict(trial=trial,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def not_lookup(x,keywords,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold=threshold+1\n",
    "        if threshold<1 and threshold1>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_not_lf(keywords,name,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"not_{name}\",\n",
    "            f=not_lookup_b,\n",
    "            resources=dict(keywords=keywords,maxngram=maxngram,label=label),)  \n",
    "    \n",
    "    def not_lookup_b(x,keywords,virus,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in virus):\n",
    "                    threshold=threshold+1\n",
    "        threshold1=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold1=threshold1+1\n",
    "        if threshold<1 and threshold1>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_not_b_lf(keywords,virus,name,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"not_b_{name}\",\n",
    "            f=not_lookup_b,\n",
    "            resources=dict(keywords=keywords,virus=virus,maxngram=maxngram,label=label),)   \n",
    "    \n",
    "    def number_lookup(x,trial,label):\n",
    "        threshold=0\n",
    "        sentlist=x.sentence.split()\n",
    "        trialindex=[i for i, e in enumerate(sentlist) if e in trial]\n",
    "        nuindex=[i for i, e in enumerate(sentlist) if str(e).isdigit()]\n",
    "        for i in trialindex:\n",
    "            for j in nuindex:\n",
    "                if i<j:\n",
    "                    threshold+=1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_number_lf(trial,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"number\",\n",
    "            f=number_lookup,\n",
    "            resources=dict(trial=trial,label=label),)\n",
    "\n",
    "   \n",
    "    \n",
    "    Norelevent = -1\n",
    "    \n",
    "    keywordfu=make_keyword_lf(keywords=keywordslist,maxngram=maxngramnu,name='keyword',label=1)    \n",
    "    virusfu=make_keyword_lf(keywords=viruslist,maxngram=maxngramnu,name='virus',label=1)\n",
    "    keywordfub=make_keyword_b_lf(keywords=keywordslist,must=mustlist,maxngram=maxngramnu,name='keyword',label=1)    \n",
    "    virusfub=make_keyword_b_lf(keywords=viruslist,must=mustlist,maxngram=maxngramnu,name='virus',label=1)\n",
    "    trialfu=make_trial_lf(trial=triallist,maxngram=maxngramnu,label=1)\n",
    "    notfu1=make_not_b_lf(keywords=mustlist,virus=keywordslist,maxngram=maxngramnu,name='notkeyword',label=0)\n",
    "    notfu2=make_not_b_lf(keywords=keywordslist,virus=triallist,maxngram=maxngramnu,name='nottrial',label=0)\n",
    "    numberfu=make_number_lf(trial=triallist,label=1)\n",
    "    \n",
    "    allweaklabf=[]\n",
    "\n",
    "    allweaklabf.append(keywordfu)\n",
    "    allweaklabf.append(virusfu)\n",
    "    allweaklabf.append(keywordfub)\n",
    "    allweaklabf.append(virusfub)\n",
    "    allweaklabf.append(trialfu)\n",
    "    allweaklabf.append(notfu1)\n",
    "    allweaklabf.append(notfu2)\n",
    "    allweaklabf.append(numberfu)\n",
    "\n",
    "    \n",
    "    return allweaklabf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119721/119721 [03:38<00:00, 547.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   j Polarity  Coverage  Overlaps  Conflicts\n",
      "keyword_keyword    0      [1]  0.028767  0.028767   0.024549\n",
      "keyword_virus      1      [1]  0.014484  0.003174   0.001328\n",
      "keyword_b_keyword  2       []  0.000000  0.000000   0.000000\n",
      "keyword_b_virus    3      [1]  0.000042  0.000042   0.000042\n",
      "trial              4      [1]  0.084321  0.014935   0.000000\n",
      "not_b_notkeyword   5      [0]  0.000326  0.000142   0.000142\n",
      "not_b_nottrial     6      [0]  0.024549  0.024549   0.024549\n",
      "number             7      [1]  0.009965  0.009965   0.000000\n"
     ]
    }
   ],
   "source": [
    "cardinalitynu=2\n",
    "allweaklabf=loop_labing(keywordslist,viruslist,triallist,mustlist,3)\n",
    "applier = PandasLFApplier(lfs=allweaklabf)\n",
    "all_train_l = applier.apply(df=gold)\n",
    "#applier = PandasParallelLFApplier(lfs=allweaklabf)\n",
    "#all_train_l = applier.apply(df=allframe1,n_parallel=40)\n",
    "report=LFAnalysis(L=all_train_l, lfs=allweaklabf).lf_summary()\n",
    "print(report)\n",
    "label_model = LabelModel(cardinality=cardinalitynu,verbose=True)\n",
    "label_model.fit(all_train_l)\n",
    "predt=label_model.predict(all_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold['label']=predt\n",
    "prob=label_model.predict_proba(all_train_l)[:,1]\n",
    "gold['prob_snokel']=prob\n",
    "gold1=gold[gold.label==1]\n",
    "gold1=gold1.drop_duplicates()\n",
    "gold1=gold1.sort_values(by='prob_snokel',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold.to_pickle('./round_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
