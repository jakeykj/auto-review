{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import os\n",
    "from snorkel.labeling import PandasLFApplier,LFAnalysis,LabelingFunction\n",
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "from snorkel.labeling.apply.dask import PandasParallelLFApplier\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "import pytrends\n",
    "from pytrends.request import TrendReq\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime, date, time\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold=pd.read_csv('hypercoagulable_sentences.csv')\n",
    "gold=gold.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sid</th>\n",
       "      <th>ncord_uid</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>… 2017; Accepted: June 2017 CASE REPORT Pneuma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[6] Patients with hypercoagulable states are p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>… relates to materials and methods for using l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Ehrlichia canis infection in dogs can cause t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>It is unknown why some dogs show signs of ble...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sid  ncord_uid  \\\n",
       "0           0    0          0   \n",
       "1           1    1          0   \n",
       "2           2    2          1   \n",
       "3           3    3          2   \n",
       "4           4    4          2   \n",
       "\n",
       "                                            sentence  \n",
       "0  … 2017; Accepted: June 2017 CASE REPORT Pneuma...  \n",
       "1  [6] Patients with hypercoagulable states are p...  \n",
       "2  … relates to materials and methods for using l...  \n",
       "3   Ehrlichia canis infection in dogs can cause t...  \n",
       "4   It is unknown why some dogs show signs of ble...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8766/8766 [00:13<00:00, 638.06it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ab=[]\n",
    "ncord=[]\n",
    "for i in tqdm(gold.ncord_uid.drop_duplicates()):\n",
    "    temp=gold[gold.ncord_uid==i]\n",
    "    tempsent=temp.sentence.values\n",
    "    tempncord=temp.ncord_uid.drop_duplicates().values[0]\n",
    "    init=''\n",
    "    for j in tempsent:\n",
    "        init=init+j\n",
    "    ab.append(init)\n",
    "    ncord.append(tempncord)\n",
    "goldab=pd.DataFrame(ncord,columns=['ncord_uid'])\n",
    "goldab['abstract']=ab\n",
    "goldab=goldab.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'health services','basic science','diagnostic','prevention','screening','device'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "triallist=['single group assignment','parallel assignment','crossover assignment','sequential sssignment','factorial assignment'\n",
    "           ,'cohort','case only','case-control','case control','ecologic or Community','family based'  \n",
    "         ,'open label','double blind','single blind','triple blind','quadruple blind',\n",
    "         'double-blind','single-blind','triple-blind','quadruple-blind'\n",
    "          ,'treatment','supportive care'\n",
    "        ,'randomized','non-Randomized','non-Randomized'\n",
    "         ]\n",
    "\n",
    "keywordslist=['coagulation','D-dimer','thromboelastometry','anticoagulants','venous thromboembolism','clot formation time'\n",
    ",'Maximum Clot Firmness', 'PT', 'aPTT', 'thrombin time','platelet','fibrinogen','antiphospholipid antibody',\n",
    "'heparin induced thrombocytopenia','prothrombin time','platelet count','factor v','factor ii','protein c','protein s',\n",
    "'antithrombin iii','leiden/apc','c-reactive protein','coagulopathy','disseminated intravascular coagulation',\n",
    "'thrombotic microangiopathy','thrombotic manifestations','sic score','venous thromboembolic','arterial thrombosis'\n",
    ",'thrombosis','heparin','tissue plasminogen activator','anticoagulants','prophylactic','anticoagulation'\n",
    "             ]\n",
    "viruslist=['covid-19','covid 19','sars cov 2','sars-cov-2','sars like cov']\n",
    "mustlist=['hypercoagulable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sid</th>\n",
       "      <th>ncord_uid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>prob_snokel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108166</th>\n",
       "      <td>108166</td>\n",
       "      <td>108166</td>\n",
       "      <td>7858</td>\n",
       "      <td>COVID-19 is an infectious disease caused by th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17719</th>\n",
       "      <td>17719</td>\n",
       "      <td>17719</td>\n",
       "      <td>1232</td>\n",
       "      <td>In all cases, medical treatment including ant...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92919</th>\n",
       "      <td>92919</td>\n",
       "      <td>92919</td>\n",
       "      <td>6768</td>\n",
       "      <td>We examine current diagnostic and treatment o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63337</th>\n",
       "      <td>63337</td>\n",
       "      <td>63337</td>\n",
       "      <td>4318</td>\n",
       "      <td>METHODS Electronic databases including MEDLIN...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120359</th>\n",
       "      <td>120359</td>\n",
       "      <td>120359</td>\n",
       "      <td>8393</td>\n",
       "      <td>12 bleeding episodes were observed; 8 occurre...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     sid  ncord_uid  \\\n",
       "108166      108166  108166       7858   \n",
       "17719        17719   17719       1232   \n",
       "92919        92919   92919       6768   \n",
       "63337        63337   63337       4318   \n",
       "120359      120359  120359       8393   \n",
       "\n",
       "                                                 sentence  label  prob_snokel  \n",
       "108166  COVID-19 is an infectious disease caused by th...      1     0.999999  \n",
       "17719    In all cases, medical treatment including ant...      1     0.999998  \n",
       "92919    We examine current diagnostic and treatment o...      1     0.999998  \n",
       "63337    METHODS Electronic databases including MEDLIN...      1     0.999998  \n",
       "120359   12 bleeding episodes were observed; 8 occurre...      1     0.999998  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_labing(keywordslist,viruslist,triallist,mustlist,maxngramnu):\n",
    "    \n",
    "    \n",
    "    def keyword_lookup(x,keywords,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_keyword_lf(keywords,maxngram,name,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"keyword_{name}\",\n",
    "            f=keyword_lookup,\n",
    "            resources=dict(keywords=keywords,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def keyword_lookup_b(x,keywords,must,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords) and any(word1 in wordlist  for word1 in must):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_keyword_b_lf(keywords,must,maxngram,name,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"keyword_b_{name}\",\n",
    "            f=keyword_lookup_b,\n",
    "            resources=dict(keywords=keywords,must=must,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def trial_lookup(x,trial,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in trial):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_trial_lf(trial,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"trial\",\n",
    "            f=trial_lookup,\n",
    "            resources=dict(trial=trial,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def not_lookup(x,keywords,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold=threshold+1\n",
    "        if threshold<1 and threshold1>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_not_lf(keywords,name,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"not_{name}\",\n",
    "            f=not_lookup_b,\n",
    "            resources=dict(keywords=keywords,maxngram=maxngram,label=label),)  \n",
    "    \n",
    "    def not_lookup_b(x,keywords,virus,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in virus):\n",
    "                    threshold=threshold+1\n",
    "        threshold1=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.abstract.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold1=threshold1+1\n",
    "        if threshold<1 and threshold1>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_not_b_lf(keywords,virus,name,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"not_b_{name}\",\n",
    "            f=not_lookup_b,\n",
    "            resources=dict(keywords=keywords,virus=virus,maxngram=maxngram,label=label),)   \n",
    "    \n",
    "    def number_lookup(x,trial,label):\n",
    "        threshold=0\n",
    "        sentlist=x.abstract.split()\n",
    "        trialindex=[i for i, e in enumerate(sentlist) if e in trial]\n",
    "        nuindex=[i for i, e in enumerate(sentlist) if str(e).isdigit()]\n",
    "        for i in trialindex:\n",
    "            for j in nuindex:\n",
    "                if i<j:\n",
    "                    threshold+=1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_number_lf(trial,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"number\",\n",
    "            f=number_lookup,\n",
    "            resources=dict(trial=trial,label=label),)\n",
    "\n",
    "   \n",
    "    \n",
    "    Norelevent = -1\n",
    "    \n",
    "    keywordfu=make_keyword_lf(keywords=keywordslist,maxngram=maxngramnu,name='keyword',label=1)    \n",
    "    virusfu=make_keyword_lf(keywords=viruslist,maxngram=maxngramnu,name='virus',label=1)\n",
    "    keywordfub=make_keyword_b_lf(keywords=keywordslist,must=mustlist,maxngram=maxngramnu,name='keyword',label=1)    \n",
    "    virusfub=make_keyword_b_lf(keywords=viruslist,must=mustlist,maxngram=maxngramnu,name='virus',label=1)\n",
    "    trialfu=make_trial_lf(trial=triallist,maxngram=maxngramnu,label=1)\n",
    "    notfu1=make_not_b_lf(keywords=mustlist,virus=keywordslist,maxngram=maxngramnu,name='notkeyword',label=0)\n",
    "    notfu2=make_not_b_lf(keywords=keywordslist,virus=triallist,maxngram=maxngramnu,name='nottrial',label=0)\n",
    "    numberfu=make_number_lf(trial=triallist,label=1)\n",
    "    \n",
    "    allweaklabf=[]\n",
    "\n",
    "    allweaklabf.append(keywordfu)\n",
    "    allweaklabf.append(virusfu)\n",
    "    allweaklabf.append(keywordfub)\n",
    "    allweaklabf.append(virusfub)\n",
    "    allweaklabf.append(trialfu)\n",
    "    allweaklabf.append(notfu1)\n",
    "    allweaklabf.append(notfu2)\n",
    "    allweaklabf.append(numberfu)\n",
    "\n",
    "    \n",
    "    return allweaklabf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8766/8766 [02:43<00:00, 53.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   j Polarity  Coverage  Overlaps  Conflicts\n",
      "keyword_keyword    0      [1]  0.236140  0.236140   0.130504\n",
      "keyword_virus      1      [1]  0.060461  0.048597   0.004905\n",
      "keyword_b_keyword  2       []  0.000000  0.000000   0.000000\n",
      "keyword_b_virus    3      [1]  0.000570  0.000570   0.000570\n",
      "trial              4      [1]  0.621948  0.497718   0.000684\n",
      "not_b_notkeyword   5      [0]  0.001141  0.000799   0.000799\n",
      "not_b_nottrial     6      [0]  0.130504  0.130504   0.130504\n",
      "number             7      [1]  0.450605  0.450605   0.000228\n"
     ]
    }
   ],
   "source": [
    "cardinalitynu=2\n",
    "allweaklabf=loop_labing(keywordslist,viruslist,triallist,mustlist,3)\n",
    "applier = PandasLFApplier(lfs=allweaklabf)\n",
    "all_train_l = applier.apply(df=gold)\n",
    "#applier = PandasParallelLFApplier(lfs=allweaklabf)\n",
    "#all_train_l = applier.apply(df=allframe1,n_parallel=40)\n",
    "report=LFAnalysis(L=all_train_l, lfs=allweaklabf).lf_summary()\n",
    "print(report)\n",
    "label_model = LabelModel(cardinality=cardinalitynu,verbose=True)\n",
    "label_model.fit(all_train_l)\n",
    "predt=label_model.predict(all_train_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldab['label']=predt\n",
    "prob=label_model.predict_proba(all_train_l)[:,1]\n",
    "goldab['prob_snokel']=prob\n",
    "goldab1=goldab[goldab.label==1]\n",
    "goldab1=goldab1.drop_duplicates()\n",
    "goldab1=goldab1.sort_values(by='prob_snokel',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldab.to_pickle('./round_2ab.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_labing(keywordslist,viruslist,triallist,mustlist,maxngramnu):\n",
    "    \n",
    "    \n",
    "    def keyword_lookup(x,keywords,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_keyword_lf(keywords,maxngram,name,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"keyword_{name}\",\n",
    "            f=keyword_lookup,\n",
    "            resources=dict(keywords=keywords,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def keyword_lookup_b(x,keywords,must,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords) and any(word1 in wordlist  for word1 in must):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_keyword_b_lf(keywords,must,maxngram,name,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"keyword_b_{name}\",\n",
    "            f=keyword_lookup_b,\n",
    "            resources=dict(keywords=keywords,must=must,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def trial_lookup(x,trial,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in trial):\n",
    "                    threshold=threshold+1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_trial_lf(trial,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"trial\",\n",
    "            f=trial_lookup,\n",
    "            resources=dict(trial=trial,maxngram=maxngram,label=label),)\n",
    "    \n",
    "    def not_lookup(x,keywords,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold=threshold+1\n",
    "        if threshold<1 and threshold1>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_not_lf(keywords,name,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"not_{name}\",\n",
    "            f=not_lookup_b,\n",
    "            resources=dict(keywords=keywords,maxngram=maxngram,label=label),)  \n",
    "    \n",
    "    def not_lookup_b(x,keywords,virus,maxngram,label):\n",
    "        threshold=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in virus):\n",
    "                    threshold=threshold+1\n",
    "        threshold1=0\n",
    "        for i in range(maxngram):\n",
    "            gramab=ngrams(x.sentence.lower().split(), i+1)\n",
    "            for word in gramab:\n",
    "                wordlist=list(word)\n",
    "                if any(word1 in wordlist  for word1 in keywords):\n",
    "                    threshold1=threshold1+1\n",
    "        if threshold<1 and threshold1>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_not_b_lf(keywords,virus,name,maxngram,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"not_b_{name}\",\n",
    "            f=not_lookup_b,\n",
    "            resources=dict(keywords=keywords,virus=virus,maxngram=maxngram,label=label),)   \n",
    "    \n",
    "    def number_lookup(x,trial,label):\n",
    "        threshold=0\n",
    "        sentlist=x.sentence.split()\n",
    "        trialindex=[i for i, e in enumerate(sentlist) if e in trial]\n",
    "        nuindex=[i for i, e in enumerate(sentlist) if str(e).isdigit()]\n",
    "        for i in trialindex:\n",
    "            for j in nuindex:\n",
    "                if i<j:\n",
    "                    threshold+=1\n",
    "        if threshold>0:\n",
    "            return label\n",
    "        return Norelevent\n",
    "\n",
    "    def make_number_lf(trial,label=None):\n",
    "        return LabelingFunction(\n",
    "            name=f\"number\",\n",
    "            f=number_lookup,\n",
    "            resources=dict(trial=trial,label=label),)\n",
    "\n",
    "   \n",
    "    \n",
    "    Norelevent = -1\n",
    "    \n",
    "    keywordfu=make_keyword_lf(keywords=keywordslist,maxngram=maxngramnu,name='keyword',label=1)    \n",
    "    virusfu=make_keyword_lf(keywords=viruslist,maxngram=maxngramnu,name='virus',label=1)\n",
    "    keywordfub=make_keyword_b_lf(keywords=keywordslist,must=mustlist,maxngram=maxngramnu,name='keyword',label=1)    \n",
    "    virusfub=make_keyword_b_lf(keywords=viruslist,must=mustlist,maxngram=maxngramnu,name='virus',label=1)\n",
    "    trialfu=make_trial_lf(trial=triallist,maxngram=maxngramnu,label=1)\n",
    "    notfu1=make_not_b_lf(keywords=mustlist,virus=keywordslist,maxngram=maxngramnu,name='notkeyword',label=0)\n",
    "    notfu2=make_not_b_lf(keywords=keywordslist,virus=triallist,maxngram=maxngramnu,name='nottrial',label=0)\n",
    "    numberfu=make_number_lf(trial=triallist,label=1)\n",
    "    \n",
    "    allweaklabf=[]\n",
    "\n",
    "    allweaklabf.append(keywordfu)\n",
    "    allweaklabf.append(virusfu)\n",
    "    allweaklabf.append(keywordfub)\n",
    "    allweaklabf.append(virusfub)\n",
    "    allweaklabf.append(trialfu)\n",
    "    allweaklabf.append(notfu1)\n",
    "    allweaklabf.append(notfu2)\n",
    "    allweaklabf.append(numberfu)\n",
    "\n",
    "    \n",
    "    return allweaklabf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119721/119721 [03:38<00:00, 547.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   j Polarity  Coverage  Overlaps  Conflicts\n",
      "keyword_keyword    0      [1]  0.028767  0.028767   0.024549\n",
      "keyword_virus      1      [1]  0.014484  0.003174   0.001328\n",
      "keyword_b_keyword  2       []  0.000000  0.000000   0.000000\n",
      "keyword_b_virus    3      [1]  0.000042  0.000042   0.000042\n",
      "trial              4      [1]  0.084321  0.014935   0.000000\n",
      "not_b_notkeyword   5      [0]  0.000326  0.000142   0.000142\n",
      "not_b_nottrial     6      [0]  0.024549  0.024549   0.024549\n",
      "number             7      [1]  0.009965  0.009965   0.000000\n"
     ]
    }
   ],
   "source": [
    "cardinalitynu=2\n",
    "allweaklabf=loop_labing(keywordslist,viruslist,triallist,mustlist,3)\n",
    "applier = PandasLFApplier(lfs=allweaklabf)\n",
    "all_train_l = applier.apply(df=gold)\n",
    "#applier = PandasParallelLFApplier(lfs=allweaklabf)\n",
    "#all_train_l = applier.apply(df=allframe1,n_parallel=40)\n",
    "report=LFAnalysis(L=all_train_l, lfs=allweaklabf).lf_summary()\n",
    "print(report)\n",
    "label_model = LabelModel(cardinality=cardinalitynu,verbose=True)\n",
    "label_model.fit(all_train_l)\n",
    "predt=label_model.predict(all_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold['label']=predt\n",
    "prob=label_model.predict_proba(all_train_l)[:,1]\n",
    "gold['prob_snokel']=prob\n",
    "gold1=gold[gold.label==1]\n",
    "gold1=gold1.drop_duplicates()\n",
    "gold1=gold1.sort_values(by='prob_snokel',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold.to_pickle('./round_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncord_uid</th>\n",
       "      <th>abstract</th>\n",
       "      <th>label</th>\n",
       "      <th>prob_snokel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6287</th>\n",
       "      <td>12</td>\n",
       "      <td>Background and Purpose Adjunctive treatments l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>5362</td>\n",
       "      <td>Background and Purpose Adjunctive treatments l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3167</td>\n",
       "      <td>Despite treatment with prophylactic enoxapari...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>7896</td>\n",
       "      <td>Medical records information including demogra...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7068</td>\n",
       "      <td>Despite treatment with prophylactic enoxapari...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1236</td>\n",
       "      <td>Despite treatment with prophylactic enoxapari...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2169</td>\n",
       "      <td>Despite treatment with prophylactic enoxapari...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7800</td>\n",
       "      <td>Despite treatment with prophylactic enoxapari...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>Despite treatment with prophylactic enoxapari...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>16</td>\n",
       "      <td>Operative treatment was performed in 17 (85%)...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>14</td>\n",
       "      <td>Medical records information including demogra...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>8</td>\n",
       "      <td>Furthermore, serum levels of inflammation-rel...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>7877</td>\n",
       "      <td>Furthermore, serum levels of inflammation-rel...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>3348</td>\n",
       "      <td>Numerous clinical trials of mesenchymal stroma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>18</td>\n",
       "      <td>Numerous clinical trials of mesenchymal stroma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>7084</td>\n",
       "      <td>Numerous clinical trials of mesenchymal stroma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5944</th>\n",
       "      <td>2437</td>\n",
       "      <td>Numerous clinical trials of mesenchymal stroma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2291</td>\n",
       "      <td>RESULTS Twenty-five patients (44% men) underw...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>9</td>\n",
       "      <td>01) and fibrinogen was declined (P&lt;0 Comparati...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>6641</td>\n",
       "      <td>RESULTS Twenty-five patients (44% men) underw...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>15</td>\n",
       "      <td>RESULTS Twenty-five patients (44% men) underw...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>10</td>\n",
       "      <td>Comparative analysis on parameters between pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>3698</td>\n",
       "      <td>RESULTS Twenty-five patients (44% men) underw...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>7</td>\n",
       "      <td>Furthermore, serum levels of inflammation‐rel...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4</td>\n",
       "      <td>We examine current diagnostic and treatment o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2158</td>\n",
       "      <td>We examine current diagnostic and treatment o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6768</td>\n",
       "      <td>We examine current diagnostic and treatment o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>3</td>\n",
       "      <td>All these benefits of CP are expected to be b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.677391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>5902</td>\n",
       "      <td>While we agree that this interim guidance add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>5</td>\n",
       "      <td>While we agree that this interim guidance add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>8023</td>\n",
       "      <td>While we agree that this interim guidance add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>2754</td>\n",
       "      <td>While we agree that this interim guidance add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1266</td>\n",
       "      <td>While we agree that this interim guidance add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>7165</td>\n",
       "      <td>While we agree that this interim guidance add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>5904</td>\n",
       "      <td>While we agree that this interim guidance add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>4030</td>\n",
       "      <td>While we agree that this interim guidance add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>6</td>\n",
       "      <td>While we agree that this interim guidance add...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>1</td>\n",
       "      <td>… relates to materials and methods for using l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>2410</td>\n",
       "      <td>… relates to materials and methods for using l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6906</th>\n",
       "      <td>6360</td>\n",
       "      <td>… relates to materials and methods for using l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>2379</td>\n",
       "      <td>[6] Patients with hypercoagulable states are p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>7812</td>\n",
       "      <td>[6] Patients with hypercoagulable states are p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>6179</td>\n",
       "      <td>[6] Patients with hypercoagulable states are p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>0</td>\n",
       "      <td>[6] Patients with hypercoagulable states are p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>2</td>\n",
       "      <td>Assess standard hemostatic variables, platele...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>3934</td>\n",
       "      <td>Imaging revealed a left temporoparietal hemor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2331</td>\n",
       "      <td>Imaging revealed a left temporoparietal hemor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>11</td>\n",
       "      <td>Imaging revealed a left temporoparietal hemor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>7054</td>\n",
       "      <td>Imaging revealed a left temporoparietal hemor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>2994</td>\n",
       "      <td>Imaging revealed a left temporoparietal hemor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ncord_uid                                           abstract  label  \\\n",
       "6287         12  Background and Purpose Adjunctive treatments l...      1   \n",
       "4209       5362  Background and Purpose Adjunctive treatments l...      1   \n",
       "61         3167   Despite treatment with prophylactic enoxapari...      1   \n",
       "3564       7896   Medical records information including demogra...      1   \n",
       "43         7068   Despite treatment with prophylactic enoxapari...      1   \n",
       "66         1236   Despite treatment with prophylactic enoxapari...      1   \n",
       "29         2169   Despite treatment with prophylactic enoxapari...      1   \n",
       "33         7800   Despite treatment with prophylactic enoxapari...      1   \n",
       "10           13   Despite treatment with prophylactic enoxapari...      1   \n",
       "687          16   Operative treatment was performed in 17 (85%)...      1   \n",
       "6319         14   Medical records information including demogra...      1   \n",
       "2307          8   Furthermore, serum levels of inflammation-rel...      1   \n",
       "2858       7877   Furthermore, serum levels of inflammation-rel...      1   \n",
       "3796       3348  Numerous clinical trials of mesenchymal stroma...      1   \n",
       "6309         18  Numerous clinical trials of mesenchymal stroma...      1   \n",
       "5402       7084  Numerous clinical trials of mesenchymal stroma...      1   \n",
       "5944       2437  Numerous clinical trials of mesenchymal stroma...      1   \n",
       "1236       2291   RESULTS Twenty-five patients (44% men) underw...      1   \n",
       "2300          9  01) and fibrinogen was declined (P<0 Comparati...      1   \n",
       "1331       6641   RESULTS Twenty-five patients (44% men) underw...      1   \n",
       "1424         15   RESULTS Twenty-five patients (44% men) underw...      1   \n",
       "2339         10   Comparative analysis on parameters between pr...      1   \n",
       "1374       3698   RESULTS Twenty-five patients (44% men) underw...      1   \n",
       "2287          7   Furthermore, serum levels of inflammation‐rel...      1   \n",
       "59            4   We examine current diagnostic and treatment o...      1   \n",
       "60         2158   We examine current diagnostic and treatment o...      1   \n",
       "2          6768   We examine current diagnostic and treatment o...      1   \n",
       "8117          3   All these benefits of CP are expected to be b...      1   \n",
       "1117       5902   While we agree that this interim guidance add...      1   \n",
       "1118          5   While we agree that this interim guidance add...      1   \n",
       "1114       8023   While we agree that this interim guidance add...      1   \n",
       "1104       2754   While we agree that this interim guidance add...      1   \n",
       "1111       1266   While we agree that this interim guidance add...      1   \n",
       "1110       7165   While we agree that this interim guidance add...      1   \n",
       "1109       5904   While we agree that this interim guidance add...      1   \n",
       "1108       4030   While we agree that this interim guidance add...      1   \n",
       "1107          6   While we agree that this interim guidance add...      1   \n",
       "8118          1  … relates to materials and methods for using l...      1   \n",
       "7921       2410  … relates to materials and methods for using l...      1   \n",
       "6906       6360  … relates to materials and methods for using l...      1   \n",
       "2546       2379  [6] Patients with hypercoagulable states are p...      0   \n",
       "2030       7812  [6] Patients with hypercoagulable states are p...      0   \n",
       "1769       6179  [6] Patients with hypercoagulable states are p...      0   \n",
       "2066          0  [6] Patients with hypercoagulable states are p...      0   \n",
       "2311          2   Assess standard hemostatic variables, platele...      0   \n",
       "2608       3934   Imaging revealed a left temporoparietal hemor...      0   \n",
       "2447       2331   Imaging revealed a left temporoparietal hemor...      0   \n",
       "2365         11   Imaging revealed a left temporoparietal hemor...      0   \n",
       "2802       7054   Imaging revealed a left temporoparietal hemor...      0   \n",
       "2035       2994   Imaging revealed a left temporoparietal hemor...      0   \n",
       "\n",
       "      prob_snokel  \n",
       "6287     0.985477  \n",
       "4209     0.985477  \n",
       "61       0.929399  \n",
       "3564     0.929399  \n",
       "43       0.929399  \n",
       "66       0.929399  \n",
       "29       0.929399  \n",
       "33       0.929399  \n",
       "10       0.929399  \n",
       "687      0.929399  \n",
       "6319     0.929399  \n",
       "2307     0.929399  \n",
       "2858     0.929399  \n",
       "3796     0.921405  \n",
       "6309     0.921405  \n",
       "5402     0.921405  \n",
       "5944     0.921405  \n",
       "1236     0.904619  \n",
       "2300     0.904619  \n",
       "1331     0.904619  \n",
       "1424     0.904619  \n",
       "2339     0.904619  \n",
       "1374     0.904619  \n",
       "2287     0.904619  \n",
       "59       0.904619  \n",
       "60       0.904619  \n",
       "2        0.904619  \n",
       "8117     0.677391  \n",
       "1117     0.621006  \n",
       "1118     0.621006  \n",
       "1114     0.621006  \n",
       "1104     0.621006  \n",
       "1111     0.621006  \n",
       "1110     0.621006  \n",
       "1109     0.621006  \n",
       "1108     0.621006  \n",
       "1107     0.621006  \n",
       "8118     0.602035  \n",
       "7921     0.602035  \n",
       "6906     0.602035  \n",
       "2546     0.000051  \n",
       "2030     0.000051  \n",
       "1769     0.000051  \n",
       "2066     0.000051  \n",
       "2311     0.000051  \n",
       "2608     0.000003  \n",
       "2447     0.000003  \n",
       "2365     0.000003  \n",
       "2802     0.000003  \n",
       "2035     0.000003  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goldab[goldab.abstract.str.contains('hypercoagulable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold1=gold1.sort_values(by='prob_snokel',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=0\n",
    "for word in ngrams('4 years and mean BMI was 42'.split(), 3):\n",
    "    wordlist=list(word)\n",
    "    if any(word1 in wordlist  for word1 in keywords):\n",
    "        threshold=threshold+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['… 2017; Accepted: June 2017 CASE REPORT Pneumatosis intestinalis, to treat or not to treat … with prodromal abdominal angina',\n",
       "       '4 years and mean BMI was 42',\n",
       "       'The major impact produced by the severe acute respiratory syndrome coronavirus 2 (SARS‑CoV‑2) focused many researchers attention to find treatments that can suppress transmission or ameliorate the disease',\n",
       "       ' Here, we describe the antiviral effects of two molecules that alter polyamine levels: difluoromethylornithine (DFMO; also called eflornithine), which is a suicide inhibitor of ornithine decarboxylase 1 (ODC1), and diethylnorspermine (DENSpm), an activator of spermidine/spermine N1-acetyltransferase (SAT1)',\n",
       "       ' High and low mesh compactions were also achieved for 2 real patients by using the dynamic push-pull technique'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold1.head().sentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenlist=gold.text.values[1].splitlines()\n",
    "tokenlist=[i for i in tokenlist if i]\n",
    "paracat=[]\n",
    "paracot=[]\n",
    "for i in range(len(tokenlist)):\n",
    "    temp=tokenlist[i].replace(':::','')\n",
    "    nuword=len(word_tokenize(temp))\n",
    "    if nuword<=10:\n",
    "        paracat.append(temp)\n",
    "    else:\n",
    "        paracot.append(temp)\n",
    "print(len(paracat))\n",
    "print(len(paracot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paracat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize('F(ab´)2 mechanisms ::: Immunomodulation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paracat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paracat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paracot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
